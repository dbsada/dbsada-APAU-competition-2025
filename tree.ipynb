{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db8875ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test_nolabel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f40f60",
   "metadata": {},
   "source": [
    "## Exploración y limpieza del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923d64d",
   "metadata": {},
   "source": [
    "Empezamos haciendo una exploración del dataset. Para ello hemos probado la libreria `dtale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e507c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dtale\n",
    "# dtale.show(train, open_browser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd9de15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['LoanNr_ChkDgt', 'id', 'State']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4c31a",
   "metadata": {},
   "source": [
    "Tenemos que conseguir que todas las variables sean nuúmericas: `int` o `float`. Además agrupamos datos y tratamos de corregir los datos incorrectos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc3c74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ApprovalDate'] = pd.to_datetime(train['ApprovalDate'], format='%d-%b-%y')\n",
    "\n",
    "train['NewExist'] = train['NewExist'].fillna(0).astype(int)\n",
    "\n",
    "train['FranchiseCode'] = train['FranchiseCode'].astype(str)\n",
    "train['FranchiseCode'] = train['FranchiseCode'].apply(lambda x: 0 if x in {0, 1} else 1).astype(int)\n",
    "\n",
    "\n",
    "train['RevLineCr'] = train['RevLineCr'].apply(lambda x: '2' if x not in {'Y', 'N'} else ('1' if x == 'Y' else '0')).astype(int)\n",
    "\n",
    "train['LowDoc'] = train['LowDoc'].apply(lambda x: '2' if x not in {'Y', 'N'} else ('1' if x == 'Y' else '0')).astype(int)\n",
    "\n",
    "train['DisbursementDate'] = pd.to_datetime(train['DisbursementDate'], format='%d-%b-%y')\n",
    "\n",
    "train[['DisbursementGross', 'BalanceGross']] = train[['DisbursementGross', 'BalanceGross']].replace({r'\\$': '', ',': ''}, regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab0c82d",
   "metadata": {},
   "source": [
    "Lo mismo con el test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "733c15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ApprovalDate'] = pd.to_datetime(test['ApprovalDate'], format='%d-%b-%y')\n",
    "\n",
    "test['NewExist'] = test['NewExist'].fillna(0).astype(int)\n",
    "\n",
    "test['FranchiseCode'] = test['FranchiseCode'].astype(str)\n",
    "test['FranchiseCode'] = test['FranchiseCode'].apply(lambda x: 0 if x in {0, 1} else 1).astype(int)\n",
    "\n",
    "test['RevLineCr'] = test['RevLineCr'].apply(lambda x: '2' if x not in {'Y', 'N'} else ('1' if x == 'Y' else '0')).astype(int)\n",
    "\n",
    "test['LowDoc'] = test['LowDoc'].apply(lambda x: '2' if x not in {'Y', 'N'} else ('1' if x == 'Y' else '0')).astype(int)\n",
    "\n",
    "test['DisbursementDate'] = pd.to_datetime(test['DisbursementDate'], format='%d-%b-%y')\n",
    "\n",
    "test[['DisbursementGross', 'BalanceGross']] = test[['DisbursementGross', 'BalanceGross']].replace({r'\\$': '', ',': ''}, regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80e491",
   "metadata": {},
   "source": [
    "Nuestro modelo dificilmente aprenderá directamente de las fechas. Transformaremos esta información en: año, trimestre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6aabb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ApprovalYear'] = train['ApprovalDate'].dt.year\n",
    "train['ApprovalQuarter'] = train['ApprovalDate'].dt.quarter\n",
    "train['DisbursementYear'] = train['DisbursementDate'].dt.year\n",
    "train['DisbursementQuarter'] = train['DisbursementDate'].dt.quarter\n",
    "train['DaysToDisbursement'] = (train['DisbursementDate'] - train['ApprovalDate']).dt.days\n",
    "\n",
    "train = train.drop(columns=['ApprovalDate', 'DisbursementDate'])\n",
    "\n",
    "test['ApprovalYear'] = test['ApprovalDate'].dt.year\n",
    "test['ApprovalQuarter'] = test['ApprovalDate'].dt.quarter\n",
    "test['DisbursementYear'] = test['DisbursementDate'].dt.year\n",
    "test['DisbursementQuarter'] = test['DisbursementDate'].dt.quarter\n",
    "test['DaysToDisbursement'] = (test['DisbursementDate'] - test['ApprovalDate']).dt.days\n",
    "\n",
    "test = test.drop(columns=['ApprovalDate', 'DisbursementDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788205b",
   "metadata": {},
   "source": [
    "Vamos, también, a intentar sacar la información importante de los nombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c708f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "name_counts = train['Name'].value_counts()\n",
    "\n",
    "def categorize_company(name):\n",
    "    name = str(name).upper()\n",
    "    if pd.isna(name):\n",
    "        return \"Other\"\n",
    "    name = name.upper().strip()\n",
    "    \n",
    "    if re.search(r'\\b(CORP(ORATION)?|INC(ORPORATED)?|CO|COMPANY)\\b', name):\n",
    "        return \"Corporation\"\n",
    "    elif re.search(r'\\b(L\\.?L\\.?C\\.?|LIMITED|LTD|L\\.?T\\.?D\\.?)\\b', name):\n",
    "        return \"Limited\"\n",
    "    elif re.search(r'\\b(CHURCH|FOUNDATION|ASSOCIATION|NONPROFIT|CLUB)\\b', name):\n",
    "        return \"NonProfit\"\n",
    "    elif re.search(r'\\b(CITY|COUNTY|STATE|SCHOOL|UNIVERSITY|GOV(ERNMENT)?|BOARD)\\b', name):\n",
    "        return \"Government\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    \n",
    "def refine_corporation(name):\n",
    "    name = str(name).upper()\n",
    "    if \"CORP\" in name:\n",
    "        return \"CORP\"\n",
    "    elif \"INC\" in name:\n",
    "        return \"INC\"\n",
    "    elif \"CO\" in name:\n",
    "        return \"CO\"\n",
    "    elif \"COMPANY\" in name:\n",
    "        return \"COMPANY\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    \n",
    "def refine_limited(name):\n",
    "    name = str(name).upper()\n",
    "    if \"LLC\" in name:\n",
    "        return \"LLC\"\n",
    "    elif \"LTD\" in name:\n",
    "        return \"LTD\"\n",
    "    elif \"LIMITED\" in name:\n",
    "        return \"LIMITED\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "train['CompanyType'] = train['Name'].apply(categorize_company)\n",
    "train['CorpType'] = train.apply(lambda row: refine_corporation(row['Name']) if row['CompanyType'] == 'Corporation' else 'Not_Corp', axis=1)\n",
    "train['LtdType'] = train.apply(lambda row: refine_limited(row['Name']) if row['CompanyType'] == 'Limited' else 'Not_Ltd', axis=1)\n",
    "\n",
    "test['CompanyType'] = test['Name'].apply(categorize_company)\n",
    "test['CorpType'] = test.apply(lambda row: refine_corporation(row['Name']) if row['CompanyType'] == 'Corporation' else 'Not_Corp', axis=1)\n",
    "test['LtdType'] = test.apply(lambda row: refine_limited(row['Name']) if row['CompanyType'] == 'Limited' else 'Not_Ltd', axis=1)\n",
    "\n",
    "train['CompanyType'] = LabelEncoder().fit_transform(train['CompanyType'])\n",
    "train['CorpType'] = LabelEncoder().fit_transform(train['CorpType'])\n",
    "train['LtdType'] = LabelEncoder().fit_transform(train['LtdType'])\n",
    "\n",
    "test['CompanyType'] = LabelEncoder().fit_transform(test['CompanyType'])\n",
    "test['CorpType'] = LabelEncoder().fit_transform(test['CorpType'])\n",
    "test['LtdType'] = LabelEncoder().fit_transform(test['LtdType'])\n",
    "\n",
    "# train = train.drop(columns='Name')\n",
    "# test = test.drop(columns='Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b7004e",
   "metadata": {},
   "source": [
    "Agrupamos también las ciudades y estados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7697c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "contador_ciudades = train['City'].value_counts()\n",
    "contador_bank_states = train['BankState'].value_counts()\n",
    "umbral = 60\n",
    "\n",
    "otras = contador_ciudades[contador_ciudades < umbral].index\n",
    "train['City'] = train['City'].replace(otras, 'OTHER_CITY')\n",
    "test['City'] = test['City'].replace(otras, 'OTHER_CITY')\n",
    "\n",
    "otras_bank_states = contador_bank_states[contador_bank_states < umbral].index\n",
    "train['BankState'] = train['BankState'].replace(otras_bank_states, 'OTHER_BANKSTATE')\n",
    "test['BankState'] = test['BankState'].replace(otras_bank_states, 'OTHER_BANKSTATE')\n",
    "\n",
    "train['City'] = LabelEncoder().fit_transform(train['City'])\n",
    "train['BankState'] = LabelEncoder().fit_transform(train['BankState'])\n",
    "test['City'] = LabelEncoder().fit_transform(test['City'])\n",
    "test['BankState'] = LabelEncoder().fit_transform(test['BankState'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e56c1a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.dtypes\n",
    "# train.isna().sum()\n",
    "# test.dtypes\n",
    "# test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdbc9ac",
   "metadata": {},
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "583a633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diego/Desktop/RETO APAU/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Batches: 100%|██████████| 714/714 [00:07<00:00, 97.17it/s] \n",
      "Batches: 100%|██████████| 103/103 [00:01<00:00, 100.64it/s]\n",
      "Batches: 100%|██████████| 714/714 [00:06<00:00, 106.61it/s]\n",
      "Batches: 100%|██████████| 103/103 [00:00<00:00, 114.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "n_clusters = 10\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "model_sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "train['Name'] = train['Name'].fillna('').str.upper().str.strip()\n",
    "X_embed = model_sbert.encode(train['Name'].tolist(), show_progress_bar=True)\n",
    "train['Cluster'] = kmeans.fit_predict(X_embed)\n",
    "\n",
    "test['Name'] = test['Name'].fillna('').str.upper().str.strip()\n",
    "X_embed_test = model_sbert.encode(test['Name'].tolist(), show_progress_bar=True)\n",
    "test['Cluster'] = kmeans.predict(X_embed_test)\n",
    "\n",
    "train['Bank'] = train['Bank'].fillna('').str.upper().str.strip()\n",
    "X_embed_bank = model_sbert.encode(train['Bank'].tolist(), show_progress_bar=True)\n",
    "train['Cluster-Bank'] = kmeans.fit_predict(X_embed_bank)\n",
    "\n",
    "test['Bank'] = test['Bank'].fillna('').str.upper().str.strip()\n",
    "X_embed_bank_test = model_sbert.encode(test['Bank'].tolist(), show_progress_bar=True)\n",
    "test['Cluster-Bank'] = kmeans.predict(X_embed_bank_test)\n",
    "\n",
    "train = train.drop(columns=['Name', 'Bank'])\n",
    "test = test.drop(columns=['Name', 'Bank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e4a61",
   "metadata": {},
   "source": [
    "## Arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89a14b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(drop + ['Accept'], axis=1)\n",
    "y = train['Accept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53f288aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "cv_results = cross_validate(model, X, y, cv=7, scoring='f1', n_jobs=-1, return_train_score=False, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7972ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_best_model = models[ np.argmax(f1_scores) ].predict(test.drop(drop, axis=1))\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': test['id'],\n",
    "#     'Accept': predictions_best_model\n",
    "# })\n",
    "# submission.to_csv('tree_best_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a730bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "models = cv_results['estimator']\n",
    "predictions_ensemble = np.array([model.predict(test.drop(drop, axis=1)) for model in models])\n",
    "final_preds = [1 if np.sum(predictions_ensemble[:, i]) > (predictions_ensemble.shape[0] / 2) else 0 for i in range(predictions_ensemble.shape[1])]\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'Accept': final_preds\n",
    "})\n",
    "submission.to_csv('tree_ensemble.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
