{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db8875ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test_nolabel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f40f60",
   "metadata": {},
   "source": [
    "## Exploración y limpieza del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923d64d",
   "metadata": {},
   "source": [
    "Empezamos haciendo una exploración del dataset. Para ello hemos probado la libreria `dtale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e507c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dtale\n",
    "# dtale.show(train, open_browser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9de15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['LoanNr_ChkDgt', 'id', 'State']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4c31a",
   "metadata": {},
   "source": [
    "Tenemos que conseguir que todas las variables sean nuúmericas: `int` o `float`. Además agrupamos datos y tratamos de corregir los datos incorrectos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc3c74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ApprovalDate'] = pd.to_datetime(train['ApprovalDate'], format='%d-%b-%y')\n",
    "\n",
    "train['NewExist'] = train['NewExist'].fillna(0).astype(int)\n",
    "\n",
    "train['FranchiseCode'] = train['FranchiseCode'].astype(str)\n",
    "train['FranchiseCode'] = train['FranchiseCode'].apply(lambda x: 0 if x in {0, 1} else 1).astype(int)\n",
    "\n",
    "\n",
    "train['RevLineCr'] = train['RevLineCr'].apply(lambda x: '2' if x not in {'Y', 'N'} else ('1' if x == 'Y' else '0')).astype(int)\n",
    "\n",
    "train['LowDoc'] = train['LowDoc'].apply(lambda x: '2' if x not in {'Y', 'N'} else ('1' if x == 'Y' else '0')).astype(int)\n",
    "\n",
    "train['DisbursementDate'] = pd.to_datetime(train['DisbursementDate'], format='%d-%b-%y')\n",
    "\n",
    "train[['DisbursementGross', 'BalanceGross']] = train[['DisbursementGross', 'BalanceGross']].replace({r'\\$': '', ',': ''}, regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab0c82d",
   "metadata": {},
   "source": [
    "Lo mismo con el test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "733c15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ApprovalDate'] = pd.to_datetime(test['ApprovalDate'], format='%d-%b-%y')\n",
    "\n",
    "test['NewExist'] = test['NewExist'].fillna(0).astype(int)\n",
    "\n",
    "test['FranchiseCode'] = test['FranchiseCode'].astype(str)\n",
    "test['FranchiseCode'] = test['FranchiseCode'].apply(lambda x: 0 if x in {0, 1} else 1).astype(int)\n",
    "\n",
    "test['RevLineCr'] = test['RevLineCr'].apply(lambda x: '2' if x not in {'Y', 'N'} else ('1' if x == 'Y' else '0')).astype(int)\n",
    "\n",
    "test['LowDoc'] = test['LowDoc'].apply(lambda x: '2' if x not in {'Y', 'N'} else ('1' if x == 'Y' else '0')).astype(int)\n",
    "\n",
    "test['DisbursementDate'] = pd.to_datetime(test['DisbursementDate'], format='%d-%b-%y')\n",
    "\n",
    "test[['DisbursementGross', 'BalanceGross']] = test[['DisbursementGross', 'BalanceGross']].replace({r'\\$': '', ',': ''}, regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80e491",
   "metadata": {},
   "source": [
    "Nuestro modelo dificilmente aprenderá directamente de las fechas. Transformaremos esta información en: año, trimestre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6aabb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ApprovalYear'] = train['ApprovalDate'].dt.year\n",
    "train['ApprovalQuarter'] = train['ApprovalDate'].dt.quarter\n",
    "train['DisbursementYear'] = train['DisbursementDate'].dt.year\n",
    "train['DisbursementQuarter'] = train['DisbursementDate'].dt.quarter\n",
    "train['DaysToDisbursement'] = (train['DisbursementDate'] - train['ApprovalDate']).dt.days\n",
    "\n",
    "train = train.drop(columns=['ApprovalDate', 'DisbursementDate'])\n",
    "\n",
    "test['ApprovalYear'] = test['ApprovalDate'].dt.year\n",
    "test['ApprovalQuarter'] = test['ApprovalDate'].dt.quarter\n",
    "test['DisbursementYear'] = test['DisbursementDate'].dt.year\n",
    "test['DisbursementQuarter'] = test['DisbursementDate'].dt.quarter\n",
    "test['DaysToDisbursement'] = (test['DisbursementDate'] - test['ApprovalDate']).dt.days\n",
    "\n",
    "test = test.drop(columns=['ApprovalDate', 'DisbursementDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788205b",
   "metadata": {},
   "source": [
    "Vamos, también, a intentar sacar la información importante de los nombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c708f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "name_counts = train['Name'].value_counts()\n",
    "\n",
    "def categorize_company(name):\n",
    "    name = str(name).upper()\n",
    "    if pd.isna(name):\n",
    "        return \"Other\"\n",
    "    name = name.upper().strip()\n",
    "    \n",
    "    if re.search(r'\\b(CORP(ORATION)?|INC(ORPORATED)?|CO|COMPANY)\\b', name):\n",
    "        return \"Corporation\"\n",
    "    elif re.search(r'\\b(L\\.?L\\.?C\\.?|LIMITED|LTD|L\\.?T\\.?D\\.?)\\b', name):\n",
    "        return \"Limited\"\n",
    "    elif re.search(r'\\b(CHURCH|FOUNDATION|ASSOCIATION|NONPROFIT|CLUB)\\b', name):\n",
    "        return \"NonProfit\"\n",
    "    elif re.search(r'\\b(CITY|COUNTY|STATE|SCHOOL|UNIVERSITY|GOV(ERNMENT)?|BOARD)\\b', name):\n",
    "        return \"Government\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    \n",
    "def refine_corporation(name):\n",
    "    name = str(name).upper()\n",
    "    if \"CORP\" in name:\n",
    "        return \"CORP\"\n",
    "    elif \"INC\" in name:\n",
    "        return \"INC\"\n",
    "    elif \"CO\" in name:\n",
    "        return \"CO\"\n",
    "    elif \"COMPANY\" in name:\n",
    "        return \"COMPANY\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    \n",
    "def refine_limited(name):\n",
    "    name = str(name).upper()\n",
    "    if \"LLC\" in name:\n",
    "        return \"LLC\"\n",
    "    elif \"LTD\" in name:\n",
    "        return \"LTD\"\n",
    "    elif \"LIMITED\" in name:\n",
    "        return \"LIMITED\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "train['CompanyType'] = train['Name'].apply(categorize_company)\n",
    "train['CorpType'] = train.apply(lambda row: refine_corporation(row['Name']) if row['CompanyType'] == 'Corporation' else 'Not_Corp', axis=1)\n",
    "train['LtdType'] = train.apply(lambda row: refine_limited(row['Name']) if row['CompanyType'] == 'Limited' else 'Not_Ltd', axis=1)\n",
    "\n",
    "test['CompanyType'] = test['Name'].apply(categorize_company)\n",
    "test['CorpType'] = test.apply(lambda row: refine_corporation(row['Name']) if row['CompanyType'] == 'Corporation' else 'Not_Corp', axis=1)\n",
    "test['LtdType'] = test.apply(lambda row: refine_limited(row['Name']) if row['CompanyType'] == 'Limited' else 'Not_Ltd', axis=1)\n",
    "\n",
    "# train = pd.get_dummies(train, columns=['CompanyType', 'CorpType', 'LtdType'], drop_first=True)\n",
    "# test = pd.get_dummies(test, columns=['CompanyType', 'CorpType', 'LtdType'], drop_first=True)\n",
    "\n",
    "# train = train.drop(columns='Name')\n",
    "# test = test.drop(columns='Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b7004e",
   "metadata": {},
   "source": [
    "Agrupamos también las ciudades y estados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7697c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "contador_ciudades = train['City'].value_counts()\n",
    "contador_bank_states = train['BankState'].value_counts()\n",
    "umbral = 60\n",
    "\n",
    "otras = contador_ciudades[contador_ciudades < umbral].index\n",
    "train['City'] = train['City'].replace(otras, 'OTHER_CITY')\n",
    "test['City'] = test['City'].replace(otras, 'OTHER_CITY')\n",
    "\n",
    "otras_bank_states = contador_bank_states[contador_bank_states < umbral].index\n",
    "train['BankState'] = train['BankState'].replace(otras_bank_states, 'OTHER_BANKSTATE')\n",
    "test['BankState'] = test['BankState'].replace(otras_bank_states, 'OTHER_BANKSTATE')\n",
    "\n",
    "# train = pd.get_dummies(train, columns=['City', 'BankState'], drop_first=True)\n",
    "# test = pd.get_dummies(test, columns=['City', 'BankState'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e56c1a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.dtypes\n",
    "# train.isna().sum()\n",
    "# test.dtypes\n",
    "# test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdbc9ac",
   "metadata": {},
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "583a633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diego/Desktop/RETO APAU/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Batches: 100%|██████████| 714/714 [00:07<00:00, 99.16it/s] \n",
      "Batches: 100%|██████████| 103/103 [00:01<00:00, 95.08it/s] \n",
      "Batches: 100%|██████████| 714/714 [00:07<00:00, 99.13it/s] \n",
      "Batches: 100%|██████████| 103/103 [00:01<00:00, 102.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "n_clusters = 10\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "model_sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "train['Name'] = train['Name'].fillna('').str.upper().str.strip()\n",
    "X_embed = model_sbert.encode(train['Name'].tolist(), show_progress_bar=True)\n",
    "train['Cluster'] = kmeans.fit_predict(X_embed)\n",
    "\n",
    "test['Name'] = test['Name'].fillna('').str.upper().str.strip()\n",
    "X_embed_test = model_sbert.encode(test['Name'].tolist(), show_progress_bar=True)\n",
    "test['Cluster'] = kmeans.predict(X_embed_test)\n",
    "\n",
    "train['Bank'] = train['Bank'].fillna('').str.upper().str.strip()\n",
    "X_embed_bank = model_sbert.encode(train['Bank'].tolist(), show_progress_bar=True)\n",
    "train['Cluster-Bank'] = kmeans.fit_predict(X_embed_bank)\n",
    "\n",
    "test['Bank'] = test['Bank'].fillna('').str.upper().str.strip()\n",
    "X_embed_bank_test = model_sbert.encode(test['Bank'].tolist(), show_progress_bar=True)\n",
    "test['Cluster-Bank'] = kmeans.predict(X_embed_bank_test)\n",
    "\n",
    "train = train.drop(columns=['Name', 'Bank'])\n",
    "test = test.drop(columns=['Name', 'Bank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e4a61",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b568db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "LoanNr_ChkDgt          0\n",
       "City                   0\n",
       "State                  0\n",
       "BankState              5\n",
       "ApprovalFY             0\n",
       "NoEmp                  0\n",
       "NewExist               0\n",
       "CreateJob              0\n",
       "RetainedJob            0\n",
       "FranchiseCode          0\n",
       "UrbanRural             0\n",
       "RevLineCr              0\n",
       "LowDoc                 0\n",
       "DisbursementGross      0\n",
       "BalanceGross           0\n",
       "ApprovalYear           0\n",
       "ApprovalQuarter        0\n",
       "DisbursementYear       7\n",
       "DisbursementQuarter    7\n",
       "DaysToDisbursement     7\n",
       "CompanyType            0\n",
       "CorpType               0\n",
       "LtdType                0\n",
       "Cluster                0\n",
       "Cluster-Bank           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89a14b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(drop + ['Accept'], axis=1)\n",
    "y = train['Accept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56322149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "categorical_features_list = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_features_list = X.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', \n",
    "         OneHotEncoder(handle_unknown='ignore', sparse_output=False),\n",
    "         categorical_features_list),\n",
    "        \n",
    "        ('num', \n",
    "         make_pipeline(\n",
    "                SimpleImputer(strategy='median'),\n",
    "                StandardScaler()\n",
    "            ),\n",
    "         numeric_features_list)\n",
    "    ],\n",
    "    remainder='drop' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53f288aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(\n",
    "    C=1.0,\n",
    "    kernel='rbf',\n",
    "    gamma='scale',\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fd0fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "cv_results = cross_validate(full_pipeline, X, y, cv=7, scoring='f1', n_jobs=-1, return_train_score=False, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc7972ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_best_model = models[ np.argmax(f1_scores) ].predict(test.drop(drop, axis=1))\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': test['id'],\n",
    "#     'Accept': predictions_best_model\n",
    "# })\n",
    "# submission.to_csv('tree_best_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a730bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "models = cv_results['estimator']\n",
    "predictions_ensemble = np.array([model.predict(test) for model in models])\n",
    "\n",
    "final_preds = [\n",
    "    1 if np.sum(predictions_ensemble[:, i]) > (predictions_ensemble.shape[0] / 2) else 0 \n",
    "    for i in range(predictions_ensemble.shape[1])\n",
    "]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'Accept': final_preds\n",
    "})\n",
    "submission.to_csv('SVM_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ahora votacion suave\n",
    "models = cv_results['estimator']\n",
    "prob_ensemble = np.array([model.predict_proba(test)[:, 1] for model in models])\n",
    "mean_prob = np.mean(prob_ensemble, axis=0)\n",
    "final_preds_soft = (mean_prob > 0.5).astype(int)\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'Accept': final_preds_soft\n",
    "})\n",
    "submission.to_csv('SVM_ensemble_soft.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9612deb",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cbbb567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import loguniform\n",
    "\n",
    "# param_distributions = {\n",
    "#     'classifier__C': loguniform(0.1, 100),\n",
    "#     'classifier__gamma': loguniform(0.0001, 0.1),\n",
    "# }\n",
    "\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=full_pipeline, \n",
    "#     param_distributions=param_distributions,\n",
    "#     n_iter=20,\n",
    "#     cv=5,\n",
    "#     scoring='f1',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# random_search.fit(X, y)\n",
    "\n",
    "# random_search.best_score_, random_search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
