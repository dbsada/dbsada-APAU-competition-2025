{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db8875ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test_nolabel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebf08d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    object\n",
       "LoanNr_ChkDgt          int64\n",
       "Name                  object\n",
       "City                  object\n",
       "State                 object\n",
       "Bank                  object\n",
       "BankState             object\n",
       "ApprovalDate          object\n",
       "ApprovalFY             int64\n",
       "NoEmp                  int64\n",
       "NewExist             float64\n",
       "CreateJob              int64\n",
       "RetainedJob            int64\n",
       "FranchiseCode          int64\n",
       "UrbanRural             int64\n",
       "RevLineCr             object\n",
       "LowDoc                object\n",
       "DisbursementDate      object\n",
       "DisbursementGross     object\n",
       "BalanceGross          object\n",
       "Accept                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f40f60",
   "metadata": {},
   "source": [
    "## Exploración y limpieza del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923d64d",
   "metadata": {},
   "source": [
    "Empezamos haciendo una exploración del dataset. Para ello hemos probado la libreria `dtale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85e507c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dtale\n",
    "# dtale.show(train, open_browser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd9de15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['LoanNr_ChkDgt', 'id', 'State']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4c31a",
   "metadata": {},
   "source": [
    "Tenemos que conseguir que todas las variables sean nuúmericas: `int` o `float`. Además agrupamos datos y tratamos de corregir los datos incorrectos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc3c74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ApprovalDate'] = pd.to_datetime(train['ApprovalDate'], format='%d-%b-%y')\n",
    "\n",
    "train['NewExist'] = train['NewExist'].fillna(0).astype(int)\n",
    "\n",
    "train['FranchiseCode'] = train['FranchiseCode'].astype(str)\n",
    "train['FranchiseCode'] = train['FranchiseCode'].apply(lambda x: 0 if x in {0, 1} else 1).astype(int)\n",
    "\n",
    "\n",
    "train['RevLineCr'] = train['RevLineCr'].apply(lambda x: '2' if x not in {'Y', 'N'} else ('1' if x == 'Y' else '0')).astype(int)\n",
    "\n",
    "train['LowDoc'] = train['LowDoc'].apply(lambda x: '2' if x not in {'Y', 'N'} else ('1' if x == 'Y' else '0')).astype(int)\n",
    "\n",
    "train['DisbursementDate'] = pd.to_datetime(train['DisbursementDate'], format='%d-%b-%y')\n",
    "\n",
    "train[['DisbursementGross', 'BalanceGross']] = train[['DisbursementGross', 'BalanceGross']].replace({r'\\$': '', ',': ''}, regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab0c82d",
   "metadata": {},
   "source": [
    "Lo mismo con el test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "733c15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ApprovalDate'] = pd.to_datetime(test['ApprovalDate'], format='%d-%b-%y')\n",
    "\n",
    "test['NewExist'] = test['NewExist'].fillna(0).astype(int)\n",
    "\n",
    "test['FranchiseCode'] = test['FranchiseCode'].astype(str)\n",
    "test['FranchiseCode'] = test['FranchiseCode'].apply(lambda x: 0 if x in {0, 1} else 1).astype(int)\n",
    "\n",
    "test['RevLineCr'] = test['RevLineCr'].apply(lambda x: '2' if x not in {'Y', 'N'} else ('1' if x == 'Y' else '0')).astype(int)\n",
    "\n",
    "test['LowDoc'] = test['LowDoc'].apply(lambda x: '2' if x not in {'Y', 'N'} else ('1' if x == 'Y' else '0')).astype(int)\n",
    "\n",
    "test['DisbursementDate'] = pd.to_datetime(test['DisbursementDate'], format='%d-%b-%y')\n",
    "\n",
    "test[['DisbursementGross', 'BalanceGross']] = test[['DisbursementGross', 'BalanceGross']].replace({r'\\$': '', ',': ''}, regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80e491",
   "metadata": {},
   "source": [
    "Nuestro modelo dificilmente aprenderá directamente de las fechas. Transformaremos esta información en: año, trimestre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6aabb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ApprovalYear'] = train['ApprovalDate'].dt.year\n",
    "train['ApprovalQuarter'] = train['ApprovalDate'].dt.quarter\n",
    "train['DisbursementYear'] = train['DisbursementDate'].dt.year\n",
    "train['DisbursementQuarter'] = train['DisbursementDate'].dt.quarter\n",
    "train['DaysToDisbursement'] = (train['DisbursementDate'] - train['ApprovalDate']).dt.days\n",
    "\n",
    "train = train.drop(columns=['ApprovalDate', 'DisbursementDate'])\n",
    "\n",
    "test['ApprovalYear'] = test['ApprovalDate'].dt.year\n",
    "test['ApprovalQuarter'] = test['ApprovalDate'].dt.quarter\n",
    "test['DisbursementYear'] = test['DisbursementDate'].dt.year\n",
    "test['DisbursementQuarter'] = test['DisbursementDate'].dt.quarter\n",
    "test['DaysToDisbursement'] = (test['DisbursementDate'] - test['ApprovalDate']).dt.days\n",
    "\n",
    "test = test.drop(columns=['ApprovalDate', 'DisbursementDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788205b",
   "metadata": {},
   "source": [
    "Vamos, también, a intentar sacar la información importante de los nombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c708f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "name_counts = train['Name'].value_counts()\n",
    "\n",
    "def categorize_company(name):\n",
    "    name = str(name).upper()\n",
    "    if pd.isna(name):\n",
    "        return \"Other\"\n",
    "    name = name.upper().strip()\n",
    "    \n",
    "    if re.search(r'\\b(CORP(ORATION)?|INC(ORPORATED)?|CO|COMPANY)\\b', name):\n",
    "        return \"Corporation\"\n",
    "    elif re.search(r'\\b(L\\.?L\\.?C\\.?|LIMITED|LTD|L\\.?T\\.?D\\.?)\\b', name):\n",
    "        return \"Limited\"\n",
    "    elif re.search(r'\\b(CHURCH|FOUNDATION|ASSOCIATION|NONPROFIT|CLUB)\\b', name):\n",
    "        return \"NonProfit\"\n",
    "    elif re.search(r'\\b(CITY|COUNTY|STATE|SCHOOL|UNIVERSITY|GOV(ERNMENT)?|BOARD)\\b', name):\n",
    "        return \"Government\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    \n",
    "def refine_corporation(name):\n",
    "    name = str(name).upper()\n",
    "    if \"CORP\" in name:\n",
    "        return \"CORP\"\n",
    "    elif \"INC\" in name:\n",
    "        return \"INC\"\n",
    "    elif \"CO\" in name:\n",
    "        return \"CO\"\n",
    "    elif \"COMPANY\" in name:\n",
    "        return \"COMPANY\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    \n",
    "def refine_limited(name):\n",
    "    name = str(name).upper()\n",
    "    if \"LLC\" in name:\n",
    "        return \"LLC\"\n",
    "    elif \"LTD\" in name:\n",
    "        return \"LTD\"\n",
    "    elif \"LIMITED\" in name:\n",
    "        return \"LIMITED\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "train['CompanyType'] = train['Name'].apply(categorize_company)\n",
    "train['CorpType'] = train.apply(lambda row: refine_corporation(row['Name']) if row['CompanyType'] == 'Corporation' else 'Not_Corp', axis=1)\n",
    "train['LtdType'] = train.apply(lambda row: refine_limited(row['Name']) if row['CompanyType'] == 'Limited' else 'Not_Ltd', axis=1)\n",
    "\n",
    "test['CompanyType'] = test['Name'].apply(categorize_company)\n",
    "test['CorpType'] = test.apply(lambda row: refine_corporation(row['Name']) if row['CompanyType'] == 'Corporation' else 'Not_Corp', axis=1)\n",
    "test['LtdType'] = test.apply(lambda row: refine_limited(row['Name']) if row['CompanyType'] == 'Limited' else 'Not_Ltd', axis=1)\n",
    "\n",
    "train['CompanyType'] = LabelEncoder().fit_transform(train['CompanyType'])\n",
    "train['CorpType'] = LabelEncoder().fit_transform(train['CorpType'])\n",
    "train['LtdType'] = LabelEncoder().fit_transform(train['LtdType'])\n",
    "\n",
    "test['CompanyType'] = LabelEncoder().fit_transform(test['CompanyType'])\n",
    "test['CorpType'] = LabelEncoder().fit_transform(test['CorpType'])\n",
    "test['LtdType'] = LabelEncoder().fit_transform(test['LtdType'])\n",
    "\n",
    "# train = train.drop(columns='Name')\n",
    "# test = test.drop(columns='Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b7004e",
   "metadata": {},
   "source": [
    "Agrupamos también las ciudades y estados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7697c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "contador_ciudades = train['City'].value_counts()\n",
    "contador_bank_states = train['BankState'].value_counts()\n",
    "umbral = 60\n",
    "\n",
    "otras = contador_ciudades[contador_ciudades < umbral].index\n",
    "train['City'] = train['City'].replace(otras, 'OTHER_CITY')\n",
    "test['City'] = test['City'].replace(otras, 'OTHER_CITY')\n",
    "\n",
    "otras_bank_states = contador_bank_states[contador_bank_states < umbral].index\n",
    "train['BankState'] = train['BankState'].replace(otras_bank_states, 'OTHER_BANKSTATE')\n",
    "test['BankState'] = test['BankState'].replace(otras_bank_states, 'OTHER_BANKSTATE')\n",
    "\n",
    "train['City'] = LabelEncoder().fit_transform(train['City'])\n",
    "train['BankState'] = LabelEncoder().fit_transform(train['BankState'])\n",
    "test['City'] = LabelEncoder().fit_transform(test['City'])\n",
    "test['BankState'] = LabelEncoder().fit_transform(test['BankState'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e56c1a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.dtypes\n",
    "# train.isna().sum()\n",
    "# test.dtypes\n",
    "# test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdbc9ac",
   "metadata": {},
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "583a633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 714/714 [00:07<00:00, 99.83it/s] \n",
      "Batches: 100%|██████████| 103/103 [00:01<00:00, 101.40it/s]\n",
      "Batches: 100%|██████████| 714/714 [00:06<00:00, 108.45it/s]\n",
      "Batches: 100%|██████████| 103/103 [00:00<00:00, 113.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "n_clusters = 10\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "model_sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "train['Name'] = train['Name'].fillna('').str.upper().str.strip()\n",
    "X_embed = model_sbert.encode(train['Name'].tolist(), show_progress_bar=True)\n",
    "train['Cluster'] = kmeans.fit_predict(X_embed)\n",
    "\n",
    "test['Name'] = test['Name'].fillna('').str.upper().str.strip()\n",
    "X_embed_test = model_sbert.encode(test['Name'].tolist(), show_progress_bar=True)\n",
    "test['Cluster'] = kmeans.predict(X_embed_test)\n",
    "\n",
    "train['Bank'] = train['Bank'].fillna('').str.upper().str.strip()\n",
    "X_embed_bank = model_sbert.encode(train['Bank'].tolist(), show_progress_bar=True)\n",
    "train['Cluster-Bank'] = kmeans.fit_predict(X_embed_bank)\n",
    "\n",
    "test['Bank'] = test['Bank'].fillna('').str.upper().str.strip()\n",
    "X_embed_bank_test = model_sbert.encode(test['Bank'].tolist(), show_progress_bar=True)\n",
    "test['Cluster-Bank'] = kmeans.predict(X_embed_bank_test)\n",
    "\n",
    "train = train.drop(columns=['Name', 'Bank'])\n",
    "test = test.drop(columns=['Name', 'Bank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e4a61",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89a14b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(drop + ['Accept'], axis=1)\n",
    "y = train['Accept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53f288aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    5.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    5.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    5.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    5.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    5.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    5.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    5.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "cv_results = cross_validate(model, X, y, cv=7, scoring='f1', n_jobs=-1, return_train_score=False, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc7972ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_best_model = models[ np.argmax(f1_scores) ].predict(test.drop(drop, axis=1))\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': test['id'],\n",
    "#     'Accept': predictions_best_model\n",
    "# })\n",
    "# submission.to_csv('random_forest_best_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a730bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "models = cv_results['estimator']\n",
    "predictions_ensemble = np.array([model.predict(test.drop(drop, axis=1)) for model in models])\n",
    "final_preds = [1 if np.sum(predictions_ensemble[:, i]) > (predictions_ensemble.shape[0] / 2) else 0 for i in range(predictions_ensemble.shape[1])]\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'Accept': final_preds\n",
    "})\n",
    "submission.to_csv('random_forest_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46164d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ahora votacion suave\n",
    "models = cv_results['estimator']\n",
    "prob_ensemble = np.array([model.predict_proba(test)[:, 1] for model in models])\n",
    "mean_prob = np.mean(prob_ensemble, axis=0)\n",
    "final_preds_soft = (mean_prob > 0.5).astype(int)\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'Accept': final_preds_soft\n",
    "})\n",
    "submission.to_csv('RandomForest_ensemble_soft.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd675200",
   "metadata": {},
   "source": [
    "## Random Forest Con Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6f5fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# grid_params = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [5, 8],\n",
    "#     'min_samples_split': range(2, 7, 2),\n",
    "#     'min_samples_leaf': range(1, 5)\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=RandomForestClassifier(\n",
    "#         class_weight='balanced',\n",
    "#         random_state=42\n",
    "#     ),\n",
    "#     param_grid=grid_params,\n",
    "#     scoring='f1',\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# grid_search.fit(X, y)\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "# best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3a933c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = grid_search.best_estimator_\n",
    "# predictions_best_model = best_model.predict(test.drop(drop, axis=1))\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': test['id'],\n",
    "#     'Accept': predictions_best_model\n",
    "# })\n",
    "# submission.to_csv('random_forest_grid_search.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d76839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "# results_df = results_df[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "# results_df = results_df.sort_values(by='mean_test_score', ascending=False)\n",
    "# results_df.set_index('rank_test_score', inplace=True)\n",
    "# results_df.loc[9].params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
